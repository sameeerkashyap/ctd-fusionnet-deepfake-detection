â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    LIGHTNING CLASSIFICATION - QUICK REFERENCE                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ PROJECT FILES (1,822 lines total)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  __init__.py         (12 lines)   - Package initialization
  model.py            (394 lines)  - BasicImageClassifier with debugging
  datamodule.py       (217 lines)  - ImageDataModule for data loading
  train.py            (277 lines)  - Complete training script
  test_setup.py       (147 lines)  - Quick verification tests
  requirements.txt    (6 lines)    - Python dependencies
  README.md           (238 lines)  - Comprehensive documentation
  SUMMARY.md          (268 lines)  - Project overview
  ARCHITECTURE.txt    (263 lines)  - Visual architecture guide

ğŸš€ QUICK START COMMANDS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # Mac Users (Apple Silicon M1/M2/M3) ğŸ
  ./mac_quickstart.sh              # Interactive setup and training
  python check_mps.py              # Check GPU availability

  # General Setup
  # 1. Install dependencies
  cd lightning_classification
  pip install -r requirements.txt

  # 2. Run quick test
  python test_setup.py

  # 3. Train on CIFAR-10 (quick)
  python train.py --use_cifar10 --max_epochs 10

  # 4. Train on CIFAR-10 (full)
  python train.py --use_cifar10 --max_epochs 50 --batch_size 64

  # 5. Monitor with TensorBoard
  tensorboard --logdir outputs/logs

ğŸ¯ KEY FEATURES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  âœ“ PyTorch Lightning framework
  âœ“ 4 Conv blocks (3â†’32â†’64â†’128â†’256)
  âœ“ 3 FC layers (50176â†’512â†’256â†’classes)
  âœ“ Batch normalization + Dropout
  âœ“ Extensive debugging (layer-by-layer)
  âœ“ Multiple metrics (Acc, Prec, Rec, F1)
  âœ“ TensorBoard logging
  âœ“ Model checkpointing
  âœ“ Early stopping
  âœ“ Learning rate scheduling
  âœ“ Rich progress bars

ğŸ” DEBUGGING OUTPUT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Model Init:
    - Layer configurations
    - Parameter counts (~50M params)
    - Architecture summary

  Forward Pass (batch 0):
    - Input/output shapes at each layer
    - Activation statistics (min/max/mean/std)
    - Dead neuron detection
    - Gradient flow monitoring

  Training Step (batch 0):
    - Batch shapes and label distribution
    - Loss values
    - Predictions vs ground truth
    - Accuracy per batch

  Epoch End:
    - Aggregated metrics
    - Learning rate updates
    - Best model tracking

ğŸ“Š METRICS TRACKED
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Training:    Loss, Accuracy, Precision, Recall, F1-Score
  Validation:  Loss, Accuracy, Precision, Recall, F1-Score
  Testing:     Loss, Accuracy

âš™ï¸ COMMON ARGUMENTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  --data_dir PATH              Data directory (default: ./data)
  --use_cifar10                Use CIFAR-10 dataset (flag)
  --num_classes N              Number of classes (default: 10)
  --batch_size N               Batch size (default: 32)
  --max_epochs N               Max epochs (default: 50)
  --learning_rate LR           Learning rate (default: 0.001)
  --dropout_rate DR            Dropout rate (default: 0.5)
  --early_stopping_patience N  Early stop patience (default: 10)
  --output_dir PATH            Output directory (default: ./outputs)
  --experiment_name NAME       Experiment name (default: experiment_1)

ğŸ—ï¸ MODEL ARCHITECTURE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Input [B, 3, 224, 224]
    â†“
  Conv Block 1: Conv(3â†’32) â†’ BN â†’ ReLU â†’ Pool â†’ [B, 32, 112, 112]
    â†“
  Conv Block 2: Conv(32â†’64) â†’ BN â†’ ReLU â†’ Pool â†’ [B, 64, 56, 56]
    â†“
  Conv Block 3: Conv(64â†’128) â†’ BN â†’ ReLU â†’ Pool â†’ [B, 128, 28, 28]
    â†“
  Conv Block 4: Conv(128â†’256) â†’ BN â†’ ReLU â†’ Pool â†’ [B, 256, 14, 14]
    â†“
  Flatten â†’ [B, 50176]
    â†“
  FC Block 1: Linear(50176â†’512) â†’ BN â†’ ReLU â†’ Dropout
    â†“
  FC Block 2: Linear(512â†’256) â†’ BN â†’ ReLU â†’ Dropout
    â†“
  Output: Linear(256â†’classes) â†’ [B, classes]

ğŸ“¦ DEPENDENCIES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  torch>=2.0.0              PyTorch framework
  torchvision>=0.15.0       Vision datasets & transforms
  pytorch-lightning>=2.0.0  Lightning framework
  torchmetrics>=1.0.0       Metrics computation
  tensorboard>=2.13.0       Visualization
  rich>=13.0.0              Terminal output

ğŸ“ EXAMPLE USAGE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # Basic training
  python train.py --use_cifar10

  # Custom settings
  python train.py \
    --use_cifar10 \
    --batch_size 64 \
    --max_epochs 100 \
    --learning_rate 0.0001 \
    --dropout_rate 0.3 \
    --experiment_name my_experiment

  # Mixed precision training
  python train.py --use_cifar10 --precision 16

  # Custom dataset
  python train.py \
    --data_dir /path/to/dataset \
    --num_classes 5 \
    --max_epochs 50

ğŸ› TROUBLESHOOTING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Out of Memory:
    â†’ Reduce --batch_size
    â†’ Use --precision 16
    â†’ Increase --accumulate_grad_batches

  Slow Training:
    â†’ Increase --num_workers
    â†’ Use smaller --image_size
    â†’ Enable GPU

  Poor Convergence:
    â†’ Adjust --learning_rate
    â†’ Modify --dropout_rate
    â†’ Check data augmentation

ğŸ“‚ OUTPUT STRUCTURE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  outputs/
  â”œâ”€â”€ checkpoints/
  â”‚   â”œâ”€â”€ best-epoch=XX-val_loss=X.XXXX-val_acc=X.XXXX.ckpt
  â”‚   â”œâ”€â”€ last.ckpt
  â”‚   â””â”€â”€ ...
  â””â”€â”€ logs/
      â””â”€â”€ lightning_classification/
          â””â”€â”€ experiment_1/
              â””â”€â”€ events.out.tfevents.*

ğŸ¯ NEXT STEPS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  1. Run test_setup.py to verify installation
  2. Train on CIFAR-10 with default settings
  3. Monitor training with TensorBoard
  4. Experiment with hyperparameters
  5. Try your own dataset
  6. Customize architecture for your needs

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Created: November 29, 2025 | Version: 1.0.0 | Status: Ready! ğŸš€
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""
Model Architecture Visualization

BasicImageClassifier Architecture:
==================================

Input: [B, 3, 224, 224]
    |
    v
┌─────────────────────────────────────┐
│  CONV BLOCK 1                       │
│  Conv2d(3 -> 32, k=3, p=1)         │
│  BatchNorm2d(32)                    │
│  ReLU()                             │
│  MaxPool2d(2, 2)                    │
└─────────────────────────────────────┘
    | [B, 32, 112, 112]
    v
┌─────────────────────────────────────┐
│  CONV BLOCK 2                       │
│  Conv2d(32 -> 64, k=3, p=1)        │
│  BatchNorm2d(64)                    │
│  ReLU()                             │
│  MaxPool2d(2, 2)                    │
└─────────────────────────────────────┘
    | [B, 64, 56, 56]
    v
┌─────────────────────────────────────┐
│  CONV BLOCK 3                       │
│  Conv2d(64 -> 128, k=3, p=1)       │
│  BatchNorm2d(128)                   │
│  ReLU()                             │
│  MaxPool2d(2, 2)                    │
└─────────────────────────────────────┘
    | [B, 128, 28, 28]
    v
┌─────────────────────────────────────┐
│  CONV BLOCK 4                       │
│  Conv2d(128 -> 256, k=3, p=1)      │
│  BatchNorm2d(256)                   │
│  ReLU()                             │
│  MaxPool2d(2, 2)                    │
└─────────────────────────────────────┘
    | [B, 256, 14, 14]
    v
┌─────────────────────────────────────┐
│  FLATTEN                            │
│  view(B, -1)                        │
└─────────────────────────────────────┘
    | [B, 50176]
    v
┌─────────────────────────────────────┐
│  FC BLOCK 1                         │
│  Linear(50176 -> 512)               │
│  BatchNorm1d(512)                   │
│  ReLU()                             │
│  Dropout(0.5)                       │
└─────────────────────────────────────┘
    | [B, 512]
    v
┌─────────────────────────────────────┐
│  FC BLOCK 2                         │
│  Linear(512 -> 256)                 │
│  BatchNorm1d(256)                   │
│  ReLU()                             │
│  Dropout(0.5)                       │
└─────────────────────────────────────┘
    | [B, 256]
    v
┌─────────────────────────────────────┐
│  OUTPUT LAYER                       │
│  Linear(256 -> num_classes)         │
└─────────────────────────────────────┘
    | [B, num_classes]
    v
Output: Logits [B, num_classes]


Training Loop Flow:
===================

┌─────────────────────────────────────┐
│  TRAINING EPOCH START               │
│  - Print epoch number               │
│  - Reset metrics                    │
└─────────────────────────────────────┘
    |
    v
┌─────────────────────────────────────┐
│  FOR EACH BATCH:                    │
│                                     │
│  1. Get batch (x, y)                │
│  2. Forward pass (with debug)       │
│  3. Compute loss                    │
│  4. Backward pass                   │
│  5. Update weights                  │
│  6. Log metrics                     │
│  7. Print debug info (batch 0)      │
└─────────────────────────────────────┘
    |
    v
┌─────────────────────────────────────┐
│  TRAINING EPOCH END                 │
│  - Aggregate metrics                │
│  - Print summary                    │
└─────────────────────────────────────┘
    |
    v
┌─────────────────────────────────────┐
│  VALIDATION EPOCH START             │
│  - Print epoch number               │
└─────────────────────────────────────┘
    |
    v
┌─────────────────────────────────────┐
│  FOR EACH VAL BATCH:                │
│                                     │
│  1. Get batch (x, y)                │
│  2. Forward pass (no grad)          │
│  3. Compute loss                    │
│  4. Update metrics                  │
│  5. Print debug info (batch 0)      │
└─────────────────────────────────────┘
    |
    v
┌─────────────────────────────────────┐
│  VALIDATION EPOCH END               │
│  - Aggregate metrics                │
│  - Print summary                    │
│  - Check early stopping             │
│  - Update LR scheduler              │
│  - Save checkpoint if best          │
└─────────────────────────────────────┘
    |
    v
┌─────────────────────────────────────┐
│  REPEAT OR STOP                     │
│  - Continue if max_epochs not hit   │
│  - Stop if early stopping triggered │
└─────────────────────────────────────┘


Debugging Points:
=================

[MODEL INIT]
- Layer configurations
- Parameter counts
- Architecture summary

[FORWARD PASS] (batch_idx=0)
- Input shape & stats
- After each layer:
  * Output shape
  * Min/max/mean/std
  * Dead neurons count
- Final predictions

[TRAINING STEP] (batch_idx=0)
- Batch shapes
- Label distribution
- Loss value
- Predictions vs truth
- Accuracy

[VALIDATION STEP] (batch_idx=0)
- Batch shapes
- Validation loss
- Predictions vs truth
- Metrics

[EPOCH END]
- Aggregated metrics
- Learning rate
- Best model info


Metrics Tracked:
================

Training:
- Loss (per step & epoch)
- Accuracy (epoch)
- Precision (epoch)
- Recall (epoch)
- F1-Score (epoch)

Validation:
- Loss (epoch)
- Accuracy (epoch)
- Precision (epoch)
- Recall (epoch)
- F1-Score (epoch)

Testing:
- Loss (epoch)
- Accuracy (epoch)


Callbacks:
==========

1. ModelCheckpoint
   - Saves top 3 models
   - Based on val_loss
   - Saves last checkpoint

2. EarlyStopping
   - Monitors val_loss
   - Patience: 10 epochs
   - Stops if no improvement

3. LearningRateMonitor
   - Tracks LR changes
   - Logs to TensorBoard

4. RichProgressBar
   - Beautiful terminal output
   - Real-time metrics


File Structure:
===============

lightning_classification/
├── model.py              # Model definition
│   ├── BasicImageClassifier
│   │   ├── __init__()
│   │   ├── forward()
│   │   ├── training_step()
│   │   ├── validation_step()
│   │   ├── test_step()
│   │   ├── configure_optimizers()
│   │   └── epoch callbacks
│
├── datamodule.py         # Data handling
│   ├── ImageDataModule
│   │   ├── __init__()
│   │   ├── prepare_data()
│   │   ├── setup()
│   │   ├── train_dataloader()
│   │   ├── val_dataloader()
│   │   └── test_dataloader()
│
├── train.py              # Training script
│   ├── Argument parsing
│   ├── Device detection
│   ├── Data/model setup
│   ├── Callback setup
│   ├── Trainer init
│   ├── Training loop
│   └── Testing
│
├── test_setup.py         # Quick tests
│   ├── test_model()
│   ├── test_datamodule()
│   └── test_training_step()
│
└── Documentation
    ├── README.md         # Usage guide
    ├── SUMMARY.md        # Project overview
    └── requirements.txt  # Dependencies
"""
